{
 "cells": [
  {
   "cell_type": "code",
   "source": "# !pip install pyspark",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozMPye0qNQZF",
    "outputId": "f996aad1-f053-4a5f-da83-0fa24ef20255"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Assignment2 Spark loops\").getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ],
   "metadata": {
    "id": "hfAoVgXSNZbs",
    "ExecuteTime": {
     "end_time": "2025-05-17T14:15:24.793419Z",
     "start_time": "2025-05-17T14:15:21.062027Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "#\n",
    "# rdd = sc.textFile(\"/content/drive/MyDrive/pagecounts-20160101-000000_parsed.out\")\n",
    "# print(rdd.first())  # just to make sure the file is read\n",
    "\n",
    "\n",
    "rdd = sc.textFile(\"work/FCAI/BigData/spark-ass2/pagecounts-20160101-000000_parsed.out\")\n",
    "print(rdd.first())  # just to make sure the file is read"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1jDjKQN-NnUl",
    "outputId": "acb8367f-ba1a-476a-b735-509ab0046046",
    "ExecuteTime": {
     "end_time": "2025-05-17T14:15:29.956562Z",
     "start_time": "2025-05-17T14:15:27.930724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa 271_a.C 1 4675\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import re\n",
    "\n",
    "def parse_line(line):\n",
    "    try:\n",
    "        parts = line.strip().split(' ')\n",
    "        return (parts[0], parts[1], int(parts[2]), int(parts[3]))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "parsed_rdd = rdd.map(parse_line).filter(lambda x: x is not None)\n",
    "parsed_rdd.persist()\n",
    "\n",
    "\n",
    "# Q1: page size stats\n",
    "start_time = time.time()\n",
    "\n",
    "sizes = parsed_rdd.map(lambda line: line[3]).filter(lambda x: x >= 0).collect()\n",
    "\n",
    "min_size = min(sizes)\n",
    "max_size = max(sizes)\n",
    "avg_size = sum(sizes) / len(sizes) if sizes else 0\n",
    "\n",
    "print(\"Q1 (Loops) \\t min size:\", min_size, \"\\t Max size:\", max_size, \"\\t Avg size:\", avg_size)\n",
    "print(\"Q1 (Loops) \\t total time in seconds:\", time.time() - start_time, \"s\")\n",
    "\n",
    "\n",
    "# Q2: titles starting with 'The' & not 'en'\n",
    "start_time = time.time()\n",
    "\n",
    "lines = parsed_rdd.collect()\n",
    "\n",
    "the_titles = [line for line in lines if line[1].startswith(\"The\")]\n",
    "non_en_the = [line for line in the_titles if line[0] != \"en\"]\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Q2 (Loops) \\t total titles starting with 'The':\", len(the_titles))\n",
    "print(\"Q2 (Loops) \\t total non-English titles starting with 'The':\", len(non_en_the))\n",
    "print(\"Q2 (Loops) \\t total time in seconds:\", time.time() - start_time, \"s\")\n",
    "\n",
    "\n",
    "# Q3: Unique terms in page_title\n",
    "start_time = time.time()\n",
    "\n",
    "def normalize_term(term):\n",
    "    return re.sub(r'\\W+', '', term.lower())\n",
    "\n",
    "titles = parsed_rdd.map(lambda x: x[1]).collect()\n",
    "\n",
    "terms_set = set()\n",
    "for title in titles:\n",
    "    terms = title.split('_')\n",
    "    for term in terms:\n",
    "        normalized = normalize_term(term)\n",
    "        if normalized:\n",
    "            terms_set.add(normalized)\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Q3 (Loops) \\t total unique normalized terms:\", len(terms_set))\n",
    "print(\"Q3 (Loops) \\t sample terms:\", list(terms_set)[:5])\n",
    "print(\"Q3 (Loops) \\t total time in seconds:\", time.time() - start_time, \"s\")\n",
    "\n",
    "\n",
    "# Q4: Count titles\n",
    "start_time = time.time()\n",
    "\n",
    "titles = parsed_rdd.map(lambda x: x[1]).collect()\n",
    "\n",
    "title_count_dict = {}\n",
    "for title in titles:\n",
    "    title_count_dict[title] = title_count_dict.get(title, 0) + 1\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Q4 (Loops) \\t title count sample:\", list(title_count_dict.items())[:5])\n",
    "print(\"Q4 (Loops) \\t total time in seconds:\", time.time() - start_time, \"s\")\n",
    "\n",
    "\n",
    "\n",
    "# Q5: Group lines by title\n",
    "start_time = time.time()\n",
    "\n",
    "lines = parsed_rdd.collect()\n",
    "\n",
    "combined_dict = {}\n",
    "for line in lines:\n",
    "    project, title, hits, size = line\n",
    "    if title not in combined_dict:\n",
    "        combined_dict[title] = []\n",
    "    combined_dict[title].append((project, hits, size))\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Q5 (Loops) \\t sample combined titles:\")\n",
    "for k, v in list(combined_dict.items())[:5]:\n",
    "    print(f\"{k} -> {v}\")\n",
    "\n",
    "print(\"Q5 (Loops) \\t total time in seconds:\", time.time() - start_time, \"s\")\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nniViqdTN0sI",
    "outputId": "6a2bd885-3ecc-4a59-f232-e7106b9efff6",
    "ExecuteTime": {
     "end_time": "2025-05-17T14:16:28.877038Z",
     "start_time": "2025-05-17T14:15:46.859665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 (Loops) \t min size: 0 \t Max size: 141180155987 \t Avg size: 132239.56957446598\n",
      "Q1 (Loops) \t total time in seconds: 5.116133689880371 s\n",
      "\n",
      "\n",
      "\n",
      "Q2 (Loops) \t total titles starting with 'The': 45020\n",
      "Q2 (Loops) \t total non-English titles starting with 'The': 10292\n",
      "Q2 (Loops) \t total time in seconds: 2.8902223110198975 s\n",
      "\n",
      "\n",
      "\n",
      "Q3 (Loops) \t total unique normalized terms: 1689811\n",
      "Q3 (Loops) \t sample terms: ['ekel', 'specialexportabbottabad', 'specialentitydataq5934804json', 'talkmaximumgrosstakeoffweight', 'fileenusspoilsportogg']\n",
      "Q3 (Loops) \t total time in seconds: 10.373650074005127 s\n",
      "\n",
      "\n",
      "\n",
      "Q4 (Loops) \t title count sample: [('271_a.C', 4), ('Category:User_th', 2), ('Chiron_Elias_Krase', 6), ('Dassault_rafaele', 3), ('E.Desv', 6)]\n",
      "Q4 (Loops) \t total time in seconds: 3.753314256668091 s\n",
      "\n",
      "\n",
      "\n",
      "Q5 (Loops) \t sample combined titles:\n",
      "271_a.C -> [('aa', 1, 4675), ('az', 1, 6356), ('bcl', 1, 5068), ('be', 1, 6287)]\n",
      "Category:User_th -> [('aa', 1, 4770), ('commons.m', 1, 0)]\n",
      "Chiron_Elias_Krase -> [('aa', 1, 4694), ('az', 1, 6374), ('bg', 1, 7468), ('cho', 1, 4684), ('dz', 1, 5435), ('it', 1, 5929)]\n",
      "Dassault_rafaele -> [('aa', 2, 9372), ('en', 1, 6649), ('it', 1, 5919)]\n",
      "E.Desv -> [('aa', 1, 4662), ('arc', 1, 5210), ('ast', 1, 4825), ('fiu-vro', 1, 5237), ('fr', 1, 7057), ('ik', 1, 4548)]\n",
      "Q5 (Loops) \t total time in seconds: 19.85398244857788 s\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome To Colab",
   "toc_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
