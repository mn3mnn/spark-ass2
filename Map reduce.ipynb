{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install pyspark"
   ],
   "metadata": {
    "id": "ozMPye0qNQZF",
    "outputId": "f996aad1-f053-4a5f-da83-0fa24ef20255",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Assignment2 MapReduce\").getOrCreate()\n",
    "sc = spark.sparkContext\n"
   ],
   "metadata": {
    "id": "hfAoVgXSNZbs"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-17T13:07:11.021366Z",
     "start_time": "2025-05-17T13:07:08.614409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "#\n",
    "# rdd = sc.textFile(\"/content/drive/MyDrive/pagecounts-20160101-000000_parsed.out\")\n",
    "# print(rdd.first()) # just to make sure the file is read\n",
    "\n",
    "rdd = sc.textFile(\"work/FCAI/BigData/spark-ass2/pagecounts-20160101-000000_parsed.out\")\n",
    "print(rdd.first())  # just to make sure the file is read"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa 271_a.C 1 4675\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "# line: ProjectCode PageTitle PageHits PageSize\n",
    "def parse_line(line):\n",
    "    try:\n",
    "        parts = line.strip().split(' ')\n",
    "        return (parts[0], parts[1], int(parts[2]), int(parts[3]))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "parsed_rdd = rdd.map(parse_line).filter(lambda x: x is not None)  # filter out invalid lines\n",
    "parsed_rdd.persist() # cache the parsed RDD to use it later\n",
    "\n",
    "# Q1: page size stats\n",
    "start_time = time.time()\n",
    "\n",
    "sizes_rdd = parsed_rdd.map(lambda line: line[3]).filter(lambda x: x >= 0)\n",
    "min_size = sizes_rdd.min()\n",
    "max_size = sizes_rdd.max()\n",
    "avg_size = sizes_rdd.mean()\n",
    "\n",
    "print(\"Q1 \\t min size: \", min_size, \"\\t Max size: \", max_size, \"\\t Avg size:\", avg_size)\n",
    "print(\"Q1 \\t total time in seconds:\", time.time() - start_time, \"s\")\n",
    "\n",
    "\n",
    "# Q2: titles starting with 'The' & not 'en'\n",
    "start_time = time.time()\n",
    "\n",
    "the_titles_rdd = parsed_rdd.filter(lambda line: line[1].startswith(\"The\"))\n",
    "total_the = the_titles_rdd.count()\n",
    "non_en_the = the_titles_rdd.filter(lambda line: line[0] != \"en\").count()\n",
    "\n",
    "print('\\n\\n')\n",
    "print(\"Q2 \\t total titles starting with 'The': \", total_the)\n",
    "print(\"Q2 \\t total titles starting with 'The' & not 'en': \", non_en_the)\n",
    "print(\"Q2 \\t total time in seconds:\", time.time() - start_time, \"s\")\n",
    "\n",
    "\n",
    "# Q3: Unique terms in page_title\n",
    "start_time = time.time()\n",
    "\n",
    "def normalize_term(term):\n",
    "    # lowercase, remove non-alphanumeric characters\n",
    "    return re.sub(r'\\W+', '', term.lower())\n",
    "\n",
    "unique_terms = (parsed_rdd\n",
    "    .flatMap(lambda line: line[1].split('_'))\n",
    "                # split title by '_',\n",
    "                # flatMap to return a flattened list of terms\n",
    "    .map(normalize_term)  # normalize each term\n",
    "    .filter(lambda term: term != '')  # filter out empty terms\n",
    "    .distinct()  # get unique terms only\n",
    ")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Q3 \\t total count of unique terms: \", unique_terms.count())\n",
    "print(\"Q3 \\t unique terms: \", unique_terms.take(5))\n",
    "print(\"Q3 \\t total time in seconds:\", time.time() - start_time, \"s\")\n",
    "\n",
    "# Q4: extract title and count occurrences\n",
    "start_time = time.time()\n",
    "\n",
    "title_counts = (parsed_rdd\n",
    "                .map(lambda line: (line[1], 1))  # map line to (title, 1)\n",
    "                .reduceByKey(lambda a, b: a + b)) # a and b are the values of the same title\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Q4 \\t RDD with title counts: \", title_counts.take(5))\n",
    "print(\"Q4 \\t total time in seconds:\", time.time() - start_time, \"s\")\n",
    "\n",
    "# Q5: Group by title\n",
    "start_time = time.time()\n",
    "\n",
    "# (title, (project, hits, size))\n",
    "combined_by_title = (parsed_rdd\n",
    "    .map(lambda x: (x[1], [(x[0], x[2], x[3])]))  # value is a list to allow easy merge\n",
    "    .reduceByKey(lambda a, b: a + b) # combine lists of tuples\n",
    ")\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "print(\"Q5 \\t RDD with combined by title: \", combined_by_title.take(5))\n",
    "print(\"Q5 \\t total time in seconds:\", time.time() - start_time, \"s\")\n",
    "\n",
    "combined_by_title.saveAsTextFile(\"output/combined_by_title\")\n"
   ],
   "metadata": {
    "id": "nniViqdTN0sI",
    "outputId": "090f743b-4ef4-4c49-e1ff-9a0d4f3a8cec",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2025-05-17T13:51:08.686181Z",
     "start_time": "2025-05-17T13:50:37.911866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 \t min size:  0 \t Max size:  141180155987 \t Avg size: 132239.5695744666\n",
      "Q1 \t total time in seconds: 5.970890283584595 s\n",
      "\n",
      "\n",
      "\n",
      "Q2 \t total titles starting with 'The':  45020\n",
      "Q2 \t total titles starting with 'The' & not 'en':  10292\n",
      "Q2 \t total time in seconds: 1.1072323322296143 s\n",
      "\n",
      "\n",
      "\n",
      "Q3 \t total count of unique terms:  1689811\n",
      "Q3 \t unique terms:  ['ac', 'elias', 'edesv', 'filewiktionarylogoenpng', 'wikipedia']\n",
      "Q3 \t total time in seconds: 6.992799997329712 s\n",
      "\n",
      "\n",
      "\n",
      "Q4 \t RDD with title counts:  [('Indonesian_Wikipedia', 2), ('Special:MyLanguage/Meta:Index', 1), ('Special:WhatLinksHere/Main_Page', 8), ('Special:WhatLinksHere/MediaWiki:Edittools', 1), ('User:IlStudioso', 1)]\n",
      "Q4 \t total time in seconds: 3.0877833366394043 s\n",
      "\n",
      "\n",
      "\n",
      "Q5 \t RDD with combined by title:  [('Indonesian_Wikipedia', [('aa', 1, 4679), ('en', 1, 93905)]), ('Special:MyLanguage/Meta:Index', [('aa', 1, 4701)]), ('Special:WhatLinksHere/Main_Page', [('aa', 1, 5556), ('commons.m', 2, 15231), ('en', 5, 101406), ('en.s', 1, 8597), ('en.voy', 1, 8550), ('meta.m', 1, 11529), ('outreach.m', 1, 5698), ('simple', 3, 32145)]), ('Special:WhatLinksHere/MediaWiki:Edittools', [('aa', 1, 5139)]), ('User:IlStudioso', [('aa', 1, 6796)])]\n",
      "Q5 \t total time in seconds: 8.482000589370728 s\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome To Colab",
   "toc_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
